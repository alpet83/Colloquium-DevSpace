# Change Log

## Recent Changes (2025-07-20)
### File Preview
- Added support for viewing file contents in the frontend by clicking @attach#<file_id> or @attached_file#<file_id> in ChatContainer.vue.
- Implemented GET /chat/file_contents in file_routes.py to retrieve file content via FileManager.get_file(file_id)['content'].
- Added <dialog ref="filePreviewModal"> in ChatContainer.vue to display file content in <pre class="file-preview"> with light gray font and vertical scrolling.
- Fixed horizontal scrollbar issue in file preview by setting max-width: 90vw and overflow-x: hidden for .file-preview-modal.
- Removed excessive logging of unresolved @attach#<file_id> in formatMessage, replacing with <span class="file-unavailable">Файл <file_id> удалён или недоступен</span>.

### LLM Statistics
- Fixed token counting in llm_interactor.py by using usage.prompt_tokens instead of usage.tokens, resolving discrepancy (e.g., 4191 vs. 3870 tokens).
- Introduced llm_usage table in llm_interactor.py via DataTable with fields ts, model, sent_tokens, used_tokens, chat_id for persistent LLM usage tracking.
- Updated /chat/get_stats in chat_routes.py to fetch statistics from llm_usage using select_row for consistency, replacing chat_stats dictionary.
- Moved statistics collection from ReplicationManager to LLMInteractor to reduce module overload.

### Recursive Dialogue
- Fixed issue where recursive dialogue stopped after one LLM actor by removing break in _recursive_replicate in replication.py, allowing all LLM actors (e.g., grok3, grok4) to respond to @all.
- Verified via logs: successful dialogue between grok3 and grok4 for chat_id=1 at rql=1 and rql=2.

### Code Optimization
- Removed redundant llm_usage table creation in db.py, as DataTable in llm_interactor.py handles table creation and updates.
- Renamed handle_exception to log_and_raise and moved it to basic_logger.py as a method of BasicLogger for better specificity and integration with logging.
- Updated chat_routes.py, file_routes.py, llm_interactor.py, and replication.py to use log.logger.log_and_raise for consistent exception handling.

### Testing
- **API**:
  - `curl -H "Cookie: session_id=<your_session_id>" "http://vps.vpn:8008/api/chat/get_stats?chat_id=1"`.
  - `curl -H "Cookie: session_id=<your_session_id>" "http://vps.vpn:8008/api/chat/file_contents?file_id=1"`.
- **Database**:
  - `sqlite3 /app/data/multichat.db "SELECT * FROM llm_usage WHERE chat_id=1 ORDER BY ts DESC LIMIT 1"`.
  - `sqlite3 /app/data/multichat.db "SELECT * FROM posts WHERE chat_id=1"`.
- **Unit tests**:
  - `docker exec colloquium-core python -m unittest tests.test_replication -v`.


## Recent Changes (2025-07-25)
### File Processors
- **Enhanced FilePatchProcessor**: Updated to use `code-lines` class for `<mismatch>` tables, ensuring proper HTML escaping of `<td>` content in the frontend (`ChatContainer.vue`). This improves the display of patch mismatch errors with a consistent monospaced font and red borders.
- **New FileUndoProcessor**: Added to process `<undo file_id="..." time_back="..."/>` tags, allowing restoration of files from backups within a specified time window. Backups are stored in `/agent/projects/backups/<relative_path>.<timestamp>` and removed after successful restoration.
- **New FileReplaceProcessor**: Added to process `<replace file_id="..." find="..." to="...">` tags, enabling text replacement in files using regular expressions. Returns success message if no changes are made or updates the file with new content.
- **New FileMoveProcessor**: Added to process `<move_file file_id="..." new_name="..." overwrite="true|false"/>` tags, supporting file renaming or moving within `/app/projects`. Creates backups for link files and validates paths for security.

### Chat Visualization Improvements
- Added CSS styles for `<table class="code-lines">` in `chat.css` to support `<mismatch>` tables generated by `FilePatchProcessor`. Styles include monospaced font, red borders, and theme-aware text colors (#eee for dark, #333 for light).
- Enhanced `formatMessage` in `ChatContainer.vue` to handle `<code_patch>`, `<shell_code>`, `<stdout>`, `<stderr>`, `<mismatch>`, and `<traceback>` tags with attributes (e.g., `file_id="..."`), ensuring proper rendering in `<pre>` blocks with color-coded lines (red for removals, green for additions, gray for unchanged).
- Improved escaping of `<td>` content in `<table class="code-lines">` using `escapeHtml`, ensuring special characters (e.g., `<`, `>`) are displayed correctly.

### Chat Reactivity Improvements
- Introduced `awaited_files` as a dictionary `{ file_id: retries }` in `ChatContainer.vue` to track unknown file IDs from `@attached_file#<file_id>` references. Unresolved IDs trigger up to three `/chat/list_files` requests via `fetchFilesAndNotify` to fetch file metadata.
- Added `checkAwaitedFiles` method to initiate file list requests when new posts contain unknown file IDs, integrated with `startPolling` to run after `fetchHistory`.
- Enhanced `reformatMessages` to update message formatting after file list updates, removing resolved file IDs from `awaited_files` and decrementing retry counts for unresolved IDs.
- Added logging for file list requests and `awaited_files` updates to aid debugging (`Requested file list for awaited_files: ...`, `Updated awaited_files: ...`).


====================================== COMMIT 10.08.2025 =========================================================

Change List for Colloquium DevSpace Update
Date: 2025-08-08Purpose: Document key changes in the Colloquium DevSpace project update, focusing on LLM interaction improvements, agent processing enhancements, and parser unification. This update integrates SandwichPack compression support for better context control in multi-chat development.
Overview
This update advances the Colloquium DevSpace multi-chat tool for development, enabling LLM and agent collaboration in code editing, testing, and container execution. Changes include better handling of LLM responses, entity updates, file operations, and unified parsing with IterativeRegex for consistency across languages. The integration of SandwichPack compression ensures efficient context management, resolving issues with truncated files and improving API performance.
Changes
1. LLM Interaction and Context Assembly

File: context_assembler.py

Description:

Added filter_input method to remove <traceback> tags from messages.
Updated assemble_posts for better chat hierarchy handling and file attachment resolution.
Introduced JSON and Path imports for improved file path management.
Enhanced logging for sandwich block parsers.


File: llm_interactor.py

Description:

Updated pre-prompt loading with UTF-8 encoding support.
Added llm_usage_table for tracking LLM token usage and costs.
Enhanced _write_context_stats for logging context statistics and index JSON.
Improved send_to_llm with search parameters and usage logging.


File: llm_api.py

Description:

Added set_search_params stub for future search configuration.
Updated XAIConnection and OpenAIConnection for max_tokens and temperature settings.
Improved error handling and logging in API calls.



2. Agent Processing and Command Handling

File: llm_hands.py


Description:

Updated process_message to handle multiple processors (e.g., CommandProcessor, FileEditProcessor, CodePatchProcessor).
Added support for <user_input> tags in shell commands.
Enhanced result aggregation for handled/failed commands and agent replies.


File: post_processor.py


Description:

Updated process_response to extract quotes and handle edit commands.
Added save_quote for storing quotes in the database.
Improved quote replacement with @quote#id.


File: block_processor.py


Description:

Updated ProcessResult to include call_stack and agent_messages.
Added CommandProcessor for handling commands like ping, run_test, commit.
Enhanced pattern matching for dynamic tags.


File: shell_code.py


Description:

Updated ShellCodeProcessor for MCP API integration and user inputs.
Added timeout and project_name handling.


File: file_processors.py


Description:

Updated FileEditProcessor for file creation and modification with project support.
Added FileReplaceProcessor for full file replacement.
Added FileMoveProcessor and FileUndoProcessor for file operations.


File: patch_processor.py


Description:

Updated PatchMismatch and HunkBlock for better patch application.
Enhanced CodePatchProcessor for handling patch mismatches and backups.


File: entity_processor.py



Description:

Updated EntityUpdateProcessor for entity updates with context lines checking.


3. Other Enhancements

File: execute_commands.py


Description:

Added support for executing commands in containers with user inputs.


====================================== COMMIT 13.08.2025 =========================================================

Change Log: Context Optimization (August 2025)
Overview
This change log documents recent updates to the Colloquium DevSpace project, focusing on optimizing context size to address the GPT-5 token limit (30K tokens/min). The changes reduced context size from ~210 KB to ~88 KB, enabling reliable processing by the LLM. The updates include modifications to llm_pre_prompt.md, context_assembler.py, and llm_interactor.py.
Changes
llm_pre_prompt.md

Location: docs/llm_pre_prompt.md
Description: Added section 4 under USING MULTICHAT AGENT to allow LLMs to request files via @agent <cmd>show @attached_files:[file_id1,file_id2...]</cmd> or @attached_file#xx. This enables dynamic file inclusion within the 10-minute freshness window or last 10 posts.
Impact: Supports iterative context building, reducing manual file uploads.

context_assembler.py

Location: src/agent/context_assembler.py
Description:
Added time import and self.fresh_files = set() in __init__ to track fresh file IDs.
Modified assemble_posts to filter posts within a 10-minute window or the last 10 posts, populating self.fresh_files with file_id from @attached_file# or @attach_dir#.
Updated globals to g for consistency and replaced regex with g.ATTACHES_REGEX.


Impact: Enables selective file inclusion, reducing context size by excluding outdated files.

llm_interactor.py

Location: src/agent/managers/llm_interactor.py
Description:
Updated interact method to implement two-stage sandwich packing:
First packer.pack call generates a full index (result['index']) with all files, entities, and project datasheet.
Filtered content_blocks to include only posts (content_type=":post") or files with file_id in self.fresh_files.
Second packer.pack call creates a compact sandwich with deep_index for filtered blocks.
Added <focus> block with last_post_id and attached_files to prioritize recent context.

Summary impact: Reduces context size more than two times, ensuring compliance with GPT-5 token limits while maintaining full index for LLM orientation.